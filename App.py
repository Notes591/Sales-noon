# app.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import io

# Google sheets libs
import gspread
from google.oauth2.service_account import Credentials

# ---------------------------
# CONFIG
# ---------------------------
st.set_page_config(page_title="Noon Sales Dashboard", layout="wide")

# Google Sheet ID (from your link)
SHEET_ID = "1EIgmqX2Ku_0_tfULUc8IfvNELFj96WGz_aLoIekfluk"

# default worksheet name to try
DEFAULT_WORKSHEET_NAME = "Sales"

# local fallback file (you uploaded this earlier)
LOCAL_FALLBACK_PATH = "/mnt/data/Ù…Ø¨ÙŠØ¹Ø§ØªØµ.xlsx"

# ---------------------------
# Language selector
# ---------------------------
lang = st.sidebar.selectbox("Language / Ø§Ù„Ù„ØºØ©", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])

# small helper for translations
def t(en, ar):
    return en if lang == "English" else ar

# ---------------------------
# Function: load google sheet using service account info from st.secrets
# ---------------------------
def load_gsheet_dataframe(sheet_id, worksheet_name=None):
    """
    Attempts to load a Google Sheet using service account info stored in st.secrets["google"].
    If worksheet_name is provided, tries it first; otherwise falls back to first worksheet.
    """
    try:
        # read service account credentials from secrets
        creds_info = st.secrets["google"]
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        client = gspread.authorize(creds)

        sh = client.open_by_key(sheet_id)
        # try named worksheet
        if worksheet_name:
            try:
                ws = sh.worksheet(worksheet_name)
            except Exception:
                # fallback to first sheet
                ws = sh.get_worksheet(0)
        else:
            ws = sh.get_worksheet(0)

        data = ws.get_all_records()
        df = pd.DataFrame(data)
        return df
    except Exception as e:
        # bubble up exception to caller
        raise

# ---------------------------
# Load data: prefer Google Sheet, else fallback to local file
# ---------------------------
df = pd.DataFrame()
gs_error = None

# Try Google Sheets if secrets available
if "google" in st.secrets:
    try:
        # try using 'Sales' then fallback to first tab
        try:
            df = load_gsheet_dataframe(SHEET_ID, worksheet_name=DEFAULT_WORKSHEET_NAME)
        except Exception:
            df = load_gsheet_dataframe(SHEET_ID, worksheet_name=None)
        gs_error = None
    except Exception as e:
        gs_error = e
        df = pd.DataFrame()

# If Google loading failed or secrets not set -> try local fallback
if df.empty:
    try:
        df = pd.read_excel(LOCAL_FALLBACK_PATH)
        fallback_used = True
    except Exception:
        fallback_used = False

# If still empty -> show message and stop
if df.empty:
    st.title(t("Noon Sales Dashboard", "Ù„ÙˆØ­Ø© Ù…Ø¨ÙŠØ¹Ø§Øª Ù†ÙˆÙ†"))
    if "google" not in st.secrets:
        st.warning(t(
            "No Google service credentials found in Streamlit Secrets. Please add them, or upload an Excel file.",
            "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø¹ØªÙ…Ø§Ø¯ Google ÙÙŠ Secrets. Ø£Ø¶ÙÙ‡Ø§ Ø£Ùˆ Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel."
        ))
    else:
        st.error(t("Failed to load Google Sheet.", "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø¬ÙˆØ¬Ù„ Ø´ÙŠØª."))
        st.exception(gs_error)
    st.stop()

# ---------------------------
# Normalize columns & safe conversions
# ---------------------------
df.columns = [c.strip() for c in df.columns]

def safe_num(col):
    return pd.to_numeric(col, errors="coerce")

# try to detect common columns
col_map = {c.lower(): c for c in df.columns}

def find_col(*names):
    for n in names:
        if n.lower() in col_map:
            return col_map[n.lower()]
    return None

col_invoice = find_col("invoice_price", "invoice price", "invoice")
col_base = find_col("base_price", "base price", "price")
col_sku = find_col("partner_sku", "sku", "product_sku")
col_country = find_col("country_code", "country", "marketplace")
col_order_date = find_col("ordered_date", "order_date", "ordered date", "ordered")
col_qty = find_col("quantity", "qty", "order_qty")

# ensure sku column exists
if col_sku is None:
    df["partner_sku"] = "UNKNOWN"
    col_sku = "partner_sku"

# derived numeric columns
df["_invoice_price"] = safe_num(df[col_invoice]) if col_invoice else np.nan
df["_base_price"] = safe_num(df[col_base]) if col_base else np.nan
df["_quantity"] = safe_num(df[col_qty]).fillna(1) if col_qty else 1

# discount
df["_discount"] = df["_base_price"] - df["_invoice_price"]
df["_discount_pct"] = (df["_discount"] / df["_base_price"]) * 100

# parse dates if available
if col_order_date:
    try:
        df[col_order_date] = pd.to_datetime(df[col_order_date], errors="coerce")
    except Exception:
        pass

# ---------------------------
# HEADER + KPIs
# ---------------------------
st.title(t("ğŸ“Š Noon Sales Dashboard", "ğŸ“Š Ù„ÙˆØ­Ø© Ù…Ø¨ÙŠØ¹Ø§Øª Ù†ÙˆÙ†"))

if fallback_used:
    st.info(t("Loaded data from local fallback file (uploaded).", "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ."))

total_orders = int(df.shape[0])
total_revenue = float(df["_invoice_price"].sum(skipna=True)) if col_invoice else 0.0
avg_price = float(df["_invoice_price"].mean(skipna=True)) if col_invoice else 0.0
unique_skus = int(df[col_sku].nunique()) if col_sku else 0

c1, c2, c3, c4 = st.columns([1.2,1.2,1.2,1])
c1.metric(t("Total Orders", "Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª"), f"{total_orders:,}")
c2.metric(t("Total Revenue (SAR)", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª (SAR)"), f"{total_revenue:,.2f}")
c3.metric(t("Avg Order Value", "Ù…ØªÙˆØ³Ø· Ù‚ÙŠÙ…Ø© Ø§Ù„Ø·Ù„Ø¨"), f"{avg_price:,.2f}")
c4.metric(t("Unique SKUs", "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª (SKU)"), f"{unique_skus}")

# ---------------------------
# Filters
# ---------------------------
with st.expander(t("Filters & Segments", "Ø§Ù„ÙÙ„Ø§ØªØ± ÙˆØ§Ù„ØªÙ‚Ø³ÙŠÙ…Ø§Øª"), expanded=True):
    sku_options = np.concatenate([["All"], np.sort(df[col_sku].astype(str).unique())])
    chosen_sku = st.selectbox(t("SKU / Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØªØ¬ (SKU)", "SKU / Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØªØ¬ (SKU)"), sku_options)

    if col_country:
        country_options = np.concatenate([["All"], np.sort(df[col_country].dropna().unique())])
        chosen_country = st.selectbox(t("Country / Ø§Ù„Ø³ÙˆÙ‚", "Ø§Ù„Ø¯ÙˆÙ„Ø© / Ø§Ù„Ø³ÙˆÙ‚"), country_options)
    else:
        chosen_country = "All"

    if col_order_date:
        min_date = df[col_order_date].min()
        max_date = df[col_order_date].max()
        dr = st.date_input(t("Order date range", "Ù†Ø·Ø§Ù‚ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø·Ù„Ø¨Ø§Øª"), value=(min_date.date() if pd.notnull(min_date) else pd.Timestamp.now().date(), max_date.date() if pd.notnull(max_date) else pd.Timestamp.now().date()))
        start_date = pd.to_datetime(dr[0])
        end_date = pd.to_datetime(dr[1])
    else:
        start_date = None
        end_date = None

# apply filters
dff = df.copy()
if chosen_sku != "All":
    dff = dff = dff[dff[col_sku].astype(str) == str(chosen_sku)]
else:
    dff = dff = dff

if chosen_country != "All" and col_country:
    dff = dff[dff[col_country] == chosen_country]

if start_date is not None and end_date is not None and col_order_date:
    dff = dff[(dff[col_order_date] >= start_date) & (dff[col_order_date] <= end_date)]

# min invoice filter (optional)
min_invoice = st.sidebar.number_input(t("Min invoice price / Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø³Ø¹Ø±", "Min invoice price"), min_value=0.0, value=0.0)
if min_invoice > 0 and col_invoice:
    dff = dff[dff["_invoice_price"] >= min_invoice]

# ---------------------------
# Tabs: Overview / Discounts / SKUs / Raw
# ---------------------------
tab1, tab2, tab3, tab4 = st.tabs([t("Overview"," Ø§Ù„Ù†Ø¸Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø©"), t("Discounts","Ø§Ù„Ø®ØµÙˆÙ…Ø§Øª"), t("SKU Analysis","ØªØ­Ù„ÙŠÙ„ SKU"), t("Raw Data","Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…")])

with tab1:
    st.subheader(t("Orders & Revenue", "Ø§Ù„Ø·Ù„Ø¨Ø§Øª ÙˆØ§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª"))
    if col_order_date and col_invoice:
        series = dff.groupby(dff[col_order_date].dt.date)["_invoice_price"].agg(["count","sum"]).reset_index().rename(columns={"count":"orders","sum":"revenue"})
        fig = px.line(series, x=series.columns[0], y=["orders","revenue"], title=t("Orders & Revenue over time","Ø§Ù„Ø·Ù„Ø¨Ø§Øª ÙˆØ§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†"))
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info(t("No order date or invoice price column found for time-series.", "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø·Ù„Ø¨ Ø£Ùˆ Ø³Ø¹Ø± Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©."))

    st.subheader(t("Top SKUs by Revenue","Ø£Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª"))
    if col_invoice:
        top_skus = dff.groupby(col_sku)["_invoice_price"].agg(["count","sum"]).reset_index().rename(columns={"count":"orders","sum":"revenue"}).sort_values("revenue", ascending=False).head(20)
        fig2 = px.bar(top_skus, x=col_sku, y="revenue", hover_data=["orders"], title=t("Top SKUs by Revenue","Ø£Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª"))
        st.plotly_chart(fig2, use_container_width=True)
    else:
        st.info(t("Invoice price not found; cannot compute revenue charts.","Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø³Ø¹Ø± Ø§Ù„ÙØ§ØªÙˆØ±Ø©Ø› Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø±Ø³Ù… Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª."))

with tab2:
    st.subheader(t("Discount analysis","ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµÙˆÙ…Ø§Øª"))
    if dff["_base_price"].notna().sum() == 0:
        st.warning(t("No base/list price column found â€” cannot compute discounts.","Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ø³Ø¹Ø± Ø£Ø³Ø§Ø³ÙŠ (base_price) â€” Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®ØµÙˆÙ…Ø§Øª."))
    else:
        disc = dff[["_base_price","_invoice_price","_discount","_discount_pct", col_sku]].sort_values("_discount_pct", ascending=False)
        st.dataframe(disc.head(200), use_container_width=True)

    if dff["_discount_pct"].notna().sum() > 0:
        figd = px.histogram(dff, x="_discount_pct", nbins=30, title=t("Discount % distribution","ØªÙˆØ²ÙŠØ¹ Ù†Ø³Ø¨Ø© Ø§Ù„Ø®ØµÙ…"))
        st.plotly_chart(figd, use_container_width=True)

with tab3:
    st.subheader(t("SKU Performance","Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª"))
    sku_table = dff.groupby(col_sku).agg(
        Orders=(col_sku,"size"),
        Revenue=("_invoice_price","sum"),
        AvgPrice=("_invoice_price","mean"),
        AvgDiscountPct=("_discount_pct","mean")
    ).reset_index().sort_values("Revenue", ascending=False)
    st.dataframe(sku_table, use_container_width=True)

    st.write("---")
    st.subheader(t("Recommendations (rule-based)","ØªÙˆØµÙŠØ§Øª (Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø³ÙŠØ·Ø©)"))
    for _, row in sku_table.iterrows():
        sku = row[col_sku]
        orders = int(row["Orders"])
        rev = float(row["Revenue"]) if not np.isnan(row["Revenue"]) else 0
        avg_disc = float(row["AvgDiscountPct"]) if not np.isnan(row["AvgDiscountPct"]) else 0

        if avg_disc > 25 and orders >= 5:
            st.warning(f"{sku}: {t('Relies heavily on discounts','ÙŠØ¹ØªÙ…Ø¯ ÙƒØ«ÙŠØ±Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø®ØµÙ…')} ({avg_disc:.1f}%). {t('Try improving images/SEO before lowering price.','Ø¬Ø±Ù‘Ø¨ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ± ÙˆSEO Ù‚Ø¨Ù„ Ø§Ù„ØªØ®ÙÙŠØ¶.')}")
        elif orders < 5 and rev < 500:
            st.info(f"{sku}: {t('Low data â€” consider a small promo or ad test.','Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ù„ÙŠÙ„Ø© â€” ÙÙƒØ± ÙÙŠ Ø­Ù…Ù„Ø© ØªØ±ÙˆÙŠØ¬ÙŠØ© ØµØºÙŠØ±Ø© Ø£Ùˆ ØªØ¬Ø±Ø¨Ø© Ø¥Ø¹Ù„Ø§Ù†.')}")
        else:
            st.success(f"{sku}: {t('Stable or good performance','Ø£Ø¯Ø§Ø¡ Ù…Ø³ØªÙ‚Ø± Ø£Ùˆ Ø¬ÙŠØ¯')} ğŸ‘")

with tab4:
    st.subheader(t("Raw filtered data","Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªØµÙÙŠØ©"))
    st.dataframe(dff, use_container_width=True)

    csv_bytes = dff.to_csv(index=False).encode("utf-8")
    st.download_button(t("Download CSV","ØªØ­Ù…ÙŠÙ„ CSV"), data=csv_bytes, file_name="sales_filtered.csv", mime="text/csv")

    # Excel export
    try:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            dff.to_excel(writer, index=False, sheet_name="report")
        xlsx_bytes = output.getvalue()
        st.download_button(t("Download Excel","ØªØ­Ù…ÙŠÙ„ Excel"), data=xlsx_bytes, file_name="sales_filtered.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    except Exception:
        st.warning(t("Excel export failed. Ensure openpyxl is in requirements.","ÙØ´Ù„ ØªØµØ¯ÙŠØ± Excel. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ openpyxl ÙÙŠ requirements."))

# footer
st.write("---")
st.caption(t(f"Rows loaded: {df.shape[0]} â€” Filtered: {dff.shape[0]}","Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø­Ù…Ù‘Ù„Ø©: {df.shape[0]} â€” Ø¨Ø¹Ø¯ Ø§Ù„ØªØµÙÙŠØ©: {dff.shape[0]}"))
